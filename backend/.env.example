# =============================================================================
# SERVER CONFIGURATION
# =============================================================================
NODE_ENV=development
PORT=3001

# =============================================================================
# DATABASE
# =============================================================================
# PostgreSQL (production recommended)
# DATABASE_URL=postgresql://user:password@localhost:5432/vibeboard_storyboard

# MySQL (alternative)
# DATABASE_URL=mysql://user:password@localhost:3306/vibeboard_storyboard

# SQLite (quick start, development)
DATABASE_URL=file:./dev.db

# =============================================================================
# AI API KEYS
# =============================================================================
# Fal.ai (required for Kling, Wan, Luma, LTX, etc.)
FAL_KEY=your_fal_api_key_here

# Google AI (for Veo engines)
GOOGLE_AI_API_KEY=your_google_ai_key_here

# OpenAI (for Sora engines and vision analysis)
OPENAI_API_KEY=your_openai_key_here

# Anthropic Claude (for Story Editor screenplay generation)
# Claude excels at Pixar-style storytelling and screenplay format
# Get your key at https://console.anthropic.com/
ANTHROPIC_API_KEY=your_anthropic_key_here

# X.ai Grok (for vision analysis and technical LLM tasks)
# Faster than Claude for structured JSON output
# Get your key at https://x.ai/
XAI_API_KEY=your_xai_key_here

# =============================================================================
# PROMPT ENHANCEMENT (Uncensored LLM)
# =============================================================================
# Priority order: DeepInfra > OpenRouter > OpenAI
# Only ONE key is needed - the system will use the first available

# DeepInfra (PREFERRED - Dolphin 2.9.1 70B, ~$0.35/M, most capable uncensored)
# Get your key at https://deepinfra.com/dash/api_keys
# NOTE: DeepInfra deprecated Dolphin, now redirects to Qwen (censored) - use OpenRouter instead
# DEEPINFRA_API_KEY=your_deepinfra_key_here

# OpenRouter (FREE option - Venice Uncensored 24B, 2.2% refusal rate)
# Get your key at https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_key_here

# Optional: Override default model
# OpenRouter models (check availability at https://openrouter.ai/models):
# - cognitivecomputations/dolphin-mistral-24b-venice-edition:free (FREE, default)
# - cognitivecomputations/dolphin3.0-mistral-24b ($0.15/M)
# - cognitivecomputations/dolphin-mixtral-8x22b ($0.90/M, highest quality available)
# PROMPT_ENHANCER_MODEL=cognitivecomputations/dolphin-mistral-24b-venice-edition:free

# =============================================================================
# PROMPT ENHANCEMENT (Uncensored LLM)
# =============================================================================
# Priority order: DeepInfra > OpenRouter > OpenAI
# Only ONE key is needed - the system will use the first available

# DeepInfra (PREFERRED - Dolphin 2.9.1 70B, ~$0.35/M, most capable uncensored)
# Get your key at https://deepinfra.com/dash/api_keys
# NOTE: DeepInfra deprecated Dolphin, now redirects to Qwen (censored) - use OpenRouter instead
# DEEPINFRA_API_KEY=your_deepinfra_key_here

# OpenRouter (FREE option - Venice Uncensored 24B, 2.2% refusal rate)
# Get your key at https://openrouter.ai/keys
OPENROUTER_API_KEY=your_openrouter_key_here

# Optional: Override default model
# OpenRouter models (check availability at https://openrouter.ai/models):
# - cognitivecomputations/dolphin-mistral-24b-venice-edition:free (FREE, default)
# - cognitivecomputations/dolphin3.0-mistral-24b ($0.15/M)
# - cognitivecomputations/dolphin-mixtral-8x22b ($0.90/M, highest quality available)
# PROMPT_ENHANCER_MODEL=cognitivecomputations/dolphin-mistral-24b-venice-edition:free

# =============================================================================
# STORAGE CONFIGURATION
# =============================================================================
# Choose AWS S3 or CloudFlare R2

# AWS S3
STORAGE_PROVIDER=s3
AWS_REGION=us-east-1
AWS_ACCESS_KEY_ID=your_aws_access_key
AWS_SECRET_ACCESS_KEY=your_aws_secret_key
S3_BUCKET_NAME=vibeboard-storage
S3_CDN_URL=

# CloudFlare R2 (S3-compatible)
# STORAGE_PROVIDER=r2
# AWS_REGION=auto
# AWS_ACCESS_KEY_ID=your_r2_access_key
# AWS_SECRET_ACCESS_KEY=your_r2_secret_key
# R2_ACCOUNT_ID=your_account_id
# R2_BUCKET_NAME=vibeboard-storage
# R2_CDN_URL=

# =============================================================================
# CORS & SECURITY
# =============================================================================
CORS_ORIGIN=http://localhost:3000
JWT_SECRET=your_jwt_secret_here_change_in_production

# =============================================================================
# RATE LIMITING
# =============================================================================
RATE_LIMIT_WINDOW_MS=900000
RATE_LIMIT_MAX_REQUESTS=100

# =============================================================================
# FEATURE FLAGS
# =============================================================================
ENABLE_VEO_3=false
ENABLE_SORA_2=false
ENABLE_PROMPT_ENHANCEMENT=true

# =============================================================================
# LIMITS
# =============================================================================
MAX_ELEMENTS_PER_USER=50
MAX_SHOTS_PER_PROJECT=50
MAX_FILE_SIZE_MB=10
MAX_VIEWS_PER_ELEMENT=4

# =============================================================================
# GENERATION QUEUE
# =============================================================================
# Maximum number of generations that can run simultaneously
MAX_CONCURRENT_GENERATIONS=3

# =============================================================================
# LOCAL SERVICES
# =============================================================================
# Local MMAudio NSFW service (optional, runs on Apple Silicon Mac)
# If set, audio generation will try local service first, then fall back to Fal.ai
# MMAUDIO_LOCAL_URL=http://localhost:8765
